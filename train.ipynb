{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d862ec8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading games...\n",
      "Processing 25 games...\n",
      "Conversion failed: name 'process_game' is not defined\n",
      "Dataset error: Dataset is empty!\n"
     ]
    }
   ],
   "source": [
    "# # Updated train.py\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# import h5py\n",
    "# import numpy as np\n",
    "# from model import ChessNet\n",
    "# import os\n",
    "\n",
    "# class ChessDataset(Dataset):\n",
    "#     def __init__(self, h5_path):\n",
    "#         if not os.path.exists(h5_path):\n",
    "#             raise FileNotFoundError(f\"HDF5 file {h5_path} not found!\")\n",
    "            \n",
    "#         with h5py.File(h5_path, 'r') as hf:\n",
    "#             self.inputs = hf['inputs'][:]\n",
    "#             self.policy = hf['policy'][:]\n",
    "#             self.value = hf['value'][:]\n",
    "            \n",
    "#             if len(self.inputs) == 0:\n",
    "#                 raise ValueError(\"Dataset is empty!\")\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.inputs)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return (\n",
    "#             torch.tensor(self.inputs[idx], dtype=torch.float32),\n",
    "#             torch.tensor(self.policy[idx], dtype=torch.long),\n",
    "#             torch.tensor(self.value[idx], dtype=torch.float32)\n",
    "#         )\n",
    "\n",
    "# def train_model(h5_path, num_epochs=10, batch_size=128):\n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "#     # Initialize model\n",
    "#     model = ChessNet(num_blocks=6, channels=128).to(device)\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "#     # Loss functions\n",
    "#     policy_loss = nn.CrossEntropyLoss()\n",
    "#     value_loss = nn.MSELoss()\n",
    "    \n",
    "#     # Data loading\n",
    "#     try:\n",
    "#         dataset = ChessDataset(h5_path)\n",
    "#         print(f\"Loaded dataset with {len(dataset)} samples\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Dataset error: {str(e)}\")\n",
    "#         return\n",
    "    \n",
    "#     if len(dataset) == 0:\n",
    "#         print(\"Error: Dataset contains no samples!\")\n",
    "#         return\n",
    "    \n",
    "#     loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "#     # Training loop\n",
    "#     for epoch in range(num_epochs):\n",
    "#         total_loss = 0.0\n",
    "#         for inputs, policies, values in loader:\n",
    "#             inputs = inputs.to(device)\n",
    "#             policies = policies.to(device)\n",
    "#             values = values.to(device)\n",
    "            \n",
    "#             optimizer.zero_grad()\n",
    "            \n",
    "#             # Forward pass\n",
    "#             policy_pred, value_pred = model(inputs)\n",
    "            \n",
    "#             # Calculate losses\n",
    "#             p_loss = policy_loss(policy_pred, policies)\n",
    "#             v_loss = value_loss(value_pred.squeeze(), values)\n",
    "#             loss = p_loss + v_loss\n",
    "            \n",
    "#             # Backprop\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             total_loss += loss.item()\n",
    "        \n",
    "#         print(f'Epoch {epoch+1}/{num_epochs} Loss: {total_loss/len(loader):.4f}')\n",
    "    \n",
    "#     # Save model\n",
    "#     torch.save(model.state_dict(), 'chess_model.pth')\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # First convert PGN to HDF5\n",
    "#     from pgn_converter import convert_pgn\n",
    "    \n",
    "#     try:\n",
    "#         convert_pgn('master_games.pgn', 'chess_data.h5')\n",
    "#     except Exception as e:\n",
    "#         print(f\"Conversion failed: {str(e)}\")\n",
    "#         exit(1)\n",
    "    \n",
    "#     # Then train the model\n",
    "#     train_model('chess_data.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00384f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loaded dataset with 247 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c3381c1e5e4bf8a63e9c0a8d321115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Loss: 9.4915\n",
      "  Policy Accuracy: 0.0000\n",
      "  Value MSE: 1.0789\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b118912ffdc476fb2fc064ebb388111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:\n",
      "  Loss: 8.9740\n",
      "  Policy Accuracy: 0.0120\n",
      "  Value MSE: 1.0008\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22d61fca43f4fb3b0ff381889168beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:\n",
      "  Loss: 8.5641\n",
      "  Policy Accuracy: 0.0573\n",
      "  Value MSE: 0.9927\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1611812c84534f85a5403c5f4516ccaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:\n",
      "  Loss: 8.2078\n",
      "  Policy Accuracy: 0.1429\n",
      "  Value MSE: 0.9905\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c2648c27654b32b51a09afdcf65dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:\n",
      "  Loss: 7.8487\n",
      "  Policy Accuracy: 0.3222\n",
      "  Value MSE: 0.9845\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2e4de4f6ab4aaf84e4f50d161afeb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:\n",
      "  Loss: 7.4369\n",
      "  Policy Accuracy: 0.4649\n",
      "  Value MSE: 0.9850\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a81bfd346445fc9d8dbbbc342a3124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:\n",
      "  Loss: 7.0095\n",
      "  Policy Accuracy: 0.6312\n",
      "  Value MSE: 0.9603\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94d42e735d64672a992cdf46d224e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:\n",
      "  Loss: 6.6224\n",
      "  Policy Accuracy: 0.7439\n",
      "  Value MSE: 0.9403\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b350429aa54f2c8d2df74fb1b830a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:\n",
      "  Loss: 6.2432\n",
      "  Policy Accuracy: 0.7868\n",
      "  Value MSE: 0.9106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b374934fb241eabb88e25c371395dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:\n",
      "  Loss: 5.8657\n",
      "  Policy Accuracy: 0.8496\n",
      "  Value MSE: 0.8605\n",
      "Model saved to chess_model.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import chess\n",
    "import chess.pgn\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# First, define the model\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        return F.relu(x)\n",
    "\n",
    "class ChessNet(nn.Module):\n",
    "    def __init__(self, num_blocks=6, channels=128):\n",
    "        super().__init__()\n",
    "        # Input block\n",
    "        self.input_block = nn.Sequential(\n",
    "            nn.Conv2d(18, channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Residual tower\n",
    "        self.res_blocks = nn.Sequential(\n",
    "            *[ResidualBlock(channels) for _ in range(num_blocks)]\n",
    "        )\n",
    "        \n",
    "        # Policy head\n",
    "        self.policy_head = nn.Sequential(\n",
    "            nn.Conv2d(channels, 2, 1),\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2*8*8, 4672)\n",
    "        )\n",
    "        \n",
    "        # Value head\n",
    "        self.value_head = nn.Sequential(\n",
    "            nn.Conv2d(channels, 1, 1),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(8*8, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 3, 1, 2)  # NHWC to NCHW\n",
    "        x = self.input_block(x)\n",
    "        x = self.res_blocks(x)\n",
    "        \n",
    "        policy = self.policy_head(x)\n",
    "        value = self.value_head(x)\n",
    "        \n",
    "        return policy, value\n",
    "\n",
    "# PGN conversion functions\n",
    "def board_to_input_planes(board):\n",
    "    \"\"\"\n",
    "    Convert a chess board to input planes (18 channels, 8x8)\n",
    "    6 pieces * 2 colors * (1 for piece positions + 1 for attacks) = 24 planes\n",
    "    But we'll simplify to just 12 piece position planes + 6 attack planes\n",
    "    \"\"\"\n",
    "    piece_types = [chess.PAWN, chess.KNIGHT, chess.BISHOP, chess.ROOK, chess.QUEEN, chess.KING]\n",
    "    colors = [chess.WHITE, chess.BLACK]\n",
    "    \n",
    "    # Initialize input planes (18 planes, 8x8 board)\n",
    "    planes = np.zeros((8, 8, 18), dtype=np.float32)\n",
    "    \n",
    "    # Piece positions (12 planes: 6 piece types * 2 colors)\n",
    "    for i, piece_type in enumerate(piece_types):\n",
    "        for j, color in enumerate(colors):\n",
    "            for square in chess.SquareSet(board.pieces(piece_type, color)):\n",
    "                row, col = divmod(square, 8)\n",
    "                planes[row, col, i + j*6] = 1.0\n",
    "    \n",
    "    # Attacks (6 planes: 3 for white attacks, 3 for black attacks)\n",
    "    # We'll use 3 levels of attack: 1 attacker, 2 attackers, 3+ attackers\n",
    "    for row in range(8):\n",
    "        for col in range(8):\n",
    "            square = row * 8 + col\n",
    "            \n",
    "            # White attacks\n",
    "            attackers = board.attackers(chess.WHITE, square)\n",
    "            num_attackers = len(list(attackers))\n",
    "            if num_attackers >= 1:\n",
    "                planes[row, col, 12] = 1.0\n",
    "            if num_attackers >= 2:\n",
    "                planes[row, col, 13] = 1.0\n",
    "            if num_attackers >= 3:\n",
    "                planes[row, col, 14] = 1.0\n",
    "                \n",
    "            # Black attacks\n",
    "            attackers = board.attackers(chess.BLACK, square)\n",
    "            num_attackers = len(list(attackers))\n",
    "            if num_attackers >= 1:\n",
    "                planes[row, col, 15] = 1.0\n",
    "            if num_attackers >= 2:\n",
    "                planes[row, col, 16] = 1.0\n",
    "            if num_attackers >= 3:\n",
    "                planes[row, col, 17] = 1.0\n",
    "    \n",
    "    return planes\n",
    "\n",
    "def move_to_policy_index(move):\n",
    "    \"\"\"\n",
    "    Convert a move to a policy index (one-hot vector of size 4672)\n",
    "    We use 8x8x73 encoding:\n",
    "    - 56 queen moves (7 in each direction)\n",
    "    - 8 knight moves\n",
    "    - 9 underpromotions (3 piece types * 3 directions)\n",
    "    Total: 73 moves per square = 73 * 64 = 4672 possible moves\n",
    "    \"\"\"\n",
    "    from_square = move.from_square\n",
    "    to_square = move.to_square\n",
    "    \n",
    "    from_rank, from_file = divmod(from_square, 8)\n",
    "    to_rank, to_file = divmod(to_square, 8)\n",
    "    \n",
    "    # Calculate direction\n",
    "    rank_diff = to_rank - from_rank\n",
    "    file_diff = to_file - from_file\n",
    "    \n",
    "    # Queen moves (straight lines and diagonals)\n",
    "    if (rank_diff == 0 or file_diff == 0 or abs(rank_diff) == abs(file_diff)):\n",
    "        # Determine direction\n",
    "        if rank_diff > 0 and file_diff == 0:  # North\n",
    "            direction = 0\n",
    "        elif rank_diff > 0 and file_diff > 0:  # Northeast\n",
    "            direction = 1\n",
    "        elif rank_diff == 0 and file_diff > 0:  # East\n",
    "            direction = 2\n",
    "        elif rank_diff < 0 and file_diff > 0:  # Southeast\n",
    "            direction = 3\n",
    "        elif rank_diff < 0 and file_diff == 0:  # South\n",
    "            direction = 4\n",
    "        elif rank_diff < 0 and file_diff < 0:  # Southwest\n",
    "            direction = 5\n",
    "        elif rank_diff == 0 and file_diff < 0:  # West\n",
    "            direction = 6\n",
    "        elif rank_diff > 0 and file_diff < 0:  # Northwest\n",
    "            direction = 7\n",
    "        \n",
    "        # Distance (1-7)\n",
    "        distance = max(abs(rank_diff), abs(file_diff))\n",
    "        \n",
    "        # Index within the move encoding\n",
    "        move_index = direction * 7 + (distance - 1)\n",
    "    \n",
    "    # Knight moves\n",
    "    elif (abs(rank_diff), abs(file_diff)) in [(1, 2), (2, 1)]:\n",
    "        # Convert knight move to index (8 possible knight moves)\n",
    "        if (rank_diff, file_diff) == (2, 1):\n",
    "            knight_index = 0\n",
    "        elif (rank_diff, file_diff) == (1, 2):\n",
    "            knight_index = 1\n",
    "        elif (rank_diff, file_diff) == (-1, 2):\n",
    "            knight_index = 2\n",
    "        elif (rank_diff, file_diff) == (-2, 1):\n",
    "            knight_index = 3\n",
    "        elif (rank_diff, file_diff) == (-2, -1):\n",
    "            knight_index = 4\n",
    "        elif (rank_diff, file_diff) == (-1, -2):\n",
    "            knight_index = 5\n",
    "        elif (rank_diff, file_diff) == (1, -2):\n",
    "            knight_index = 6\n",
    "        elif (rank_diff, file_diff) == (2, -1):\n",
    "            knight_index = 7\n",
    "        \n",
    "        # Knight moves start after queen moves\n",
    "        move_index = 56 + knight_index\n",
    "    \n",
    "    # Underpromotions (excluding queen promotion which is counted as a queen move)\n",
    "    elif move.promotion is not None and move.promotion != chess.QUEEN:\n",
    "        # Direction (straight, left diagonal, right diagonal)\n",
    "        if file_diff == 0:\n",
    "            direction = 0\n",
    "        elif file_diff < 0:\n",
    "            direction = 1\n",
    "        else:\n",
    "            direction = 2\n",
    "        \n",
    "        # Piece type (knight, bishop, rook) - 1 (to get 0, 1, 2)\n",
    "        piece_idx = [chess.KNIGHT, chess.BISHOP, chess.ROOK].index(move.promotion)\n",
    "        \n",
    "        # Underpromotions start after queen and knight moves\n",
    "        move_index = 56 + 8 + piece_idx * 3 + direction\n",
    "    \n",
    "    # Any move we can't categorize (shouldn't happen with legal moves)\n",
    "    else:\n",
    "        # Default to the first move\n",
    "        move_index = 0\n",
    "    \n",
    "    # Final policy index: 73 move types per square\n",
    "    return from_square * 73 + move_index\n",
    "\n",
    "def process_game(game):\n",
    "    \"\"\"Process a game, returning (input_planes, policy, value) for training positions\"\"\"\n",
    "    inputs = []\n",
    "    policies = []\n",
    "    values = []\n",
    "    \n",
    "    board = game.board()\n",
    "    result = game.headers.get(\"Result\", \"*\")\n",
    "    \n",
    "    # Determine game outcome\n",
    "    if result == \"1-0\":\n",
    "        white_win = 1.0\n",
    "    elif result == \"0-1\":\n",
    "        white_win = -1.0\n",
    "    else:  # Draw or unfinished\n",
    "        white_win = 0.0\n",
    "    \n",
    "    for move_num, move in enumerate(game.mainline_moves()):\n",
    "        # Skip first 5 moves (10 half-moves) to focus on middlegame positions\n",
    "        if move_num < 10:\n",
    "            board.push(move)\n",
    "            continue\n",
    "            \n",
    "        # Extract features before the move is made\n",
    "        input_planes = board_to_input_planes(board)\n",
    "        \n",
    "        # Extract policy (the actual move that was played)\n",
    "        policy_index = move_to_policy_index(move)\n",
    "\n",
    "        # Value: perspective of the player to move\n",
    "        value = white_win if board.turn == chess.WHITE else -white_win\n",
    "        \n",
    "        # Store the training example\n",
    "        inputs.append(input_planes)\n",
    "        policies.append(policy_index)\n",
    "        values.append(value)\n",
    "        \n",
    "        # Make the move on the board\n",
    "        board.push(move)\n",
    "        \n",
    "        # Limit samples per game\n",
    "        if len(inputs) >= 10:\n",
    "            break\n",
    "    \n",
    "    return inputs, policies, values\n",
    "\n",
    "def convert_pgn(pgn_file, output_h5):\n",
    "    \"\"\"Convert PGN file to HDF5 format for training\"\"\"\n",
    "    if not os.path.exists(pgn_file):\n",
    "        raise FileNotFoundError(f\"PGN file {pgn_file} not found!\")\n",
    "    \n",
    "    print(f\"Reading games...\")\n",
    "    with open(pgn_file) as f:\n",
    "        # Count games first (to show progress)\n",
    "        game_count = 0\n",
    "        pos = f.tell()\n",
    "        while True:\n",
    "            game = chess.pgn.read_game(f)\n",
    "            if game is None:\n",
    "                break\n",
    "            game_count += 1\n",
    "            \n",
    "        # Reset file position\n",
    "        f.seek(pos)\n",
    "        print(f\"Processing {game_count} games...\")\n",
    "        \n",
    "        all_inputs = []\n",
    "        all_policies = []\n",
    "        all_values = []\n",
    "        \n",
    "        # Process each game\n",
    "        for _ in tqdm(range(game_count)):\n",
    "            game = chess.pgn.read_game(f)\n",
    "            if game is None:\n",
    "                break\n",
    "                \n",
    "            try:\n",
    "                inputs, policies, values = process_game(game)\n",
    "                all_inputs.extend(inputs)\n",
    "                all_policies.extend(policies)\n",
    "                all_values.extend(values) \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing game: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_inputs = np.array(all_inputs, dtype=np.float32)\n",
    "    all_policies = np.array(all_policies, dtype=np.int64)\n",
    "    all_values = np.array(all_values, dtype=np.float32)\n",
    "    \n",
    "    print(f\"Total positions: {len(all_inputs)}\")\n",
    "    \n",
    "    # Save to HDF5\n",
    "    with h5py.File(output_h5, 'w') as hf:\n",
    "        hf.create_dataset('inputs', data=all_inputs)\n",
    "        hf.create_dataset('policy', data=all_policies)\n",
    "        hf.create_dataset('value', data=all_values)\n",
    "    \n",
    "    print(f\"Data saved to {output_h5}\")\n",
    "\n",
    "# Dataset class for training\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, h5_path):\n",
    "        if not os.path.exists(h5_path):\n",
    "            raise FileNotFoundError(f\"HDF5 file {h5_path} not found!\")\n",
    "            \n",
    "        with h5py.File(h5_path, 'r') as hf:\n",
    "            self.inputs = hf['inputs'][:]\n",
    "            self.policy = hf['policy'][:]\n",
    "            self.value = hf['value'][:]\n",
    "            \n",
    "            if len(self.inputs) == 0:\n",
    "                raise ValueError(\"Dataset is empty!\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.inputs[idx], dtype=torch.float32),\n",
    "            torch.tensor(self.policy[idx], dtype=torch.long),\n",
    "            torch.tensor(self.value[idx], dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "def train_model(h5_path, model_save_path='chess_model.pth', num_epochs=10, batch_size=128, learning_rate=0.001):\n",
    "    import torch.nn.functional as F  # Import here to ensure it's available\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Initialize model\n",
    "    model = ChessNet(num_blocks=6, channels=128).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Loss functions\n",
    "    policy_loss = nn.CrossEntropyLoss()\n",
    "    value_loss = nn.MSELoss()\n",
    "    \n",
    "    # Data loading\n",
    "    try:\n",
    "        dataset = ChessDataset(h5_path)\n",
    "        print(f\"Loaded dataset with {len(dataset)} samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"Dataset error: {str(e)}\")\n",
    "        return\n",
    "    \n",
    "    if len(dataset) == 0:\n",
    "        print(\"Error: Dataset contains no samples!\")\n",
    "        return\n",
    "    \n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        policy_accuracy = 0.0\n",
    "        value_mse = 0.0\n",
    "        \n",
    "        for inputs, policies, values in tqdm(loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            inputs = inputs.to(device)\n",
    "            policies = policies.to(device)\n",
    "            values = values.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            policy_pred, value_pred = model(inputs)\n",
    "            \n",
    "            # Calculate losses\n",
    "            p_loss = policy_loss(policy_pred, policies)\n",
    "            v_loss = value_loss(value_pred.squeeze(), values)\n",
    "            loss = p_loss + v_loss\n",
    "            \n",
    "            # Backprop\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Track metrics\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Policy accuracy (top-1)\n",
    "            _, predicted = torch.max(policy_pred, 1)\n",
    "            policy_accuracy += (predicted == policies).sum().item() / len(policies)\n",
    "            \n",
    "            # Value MSE\n",
    "            value_mse += v_loss.item()\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        avg_loss = total_loss / len(loader)\n",
    "        avg_policy_acc = policy_accuracy / len(loader)\n",
    "        avg_value_mse = value_mse / len(loader)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'  Loss: {avg_loss:.4f}')\n",
    "        print(f'  Policy Accuracy: {avg_policy_acc:.4f}')\n",
    "        print(f'  Value MSE: {avg_value_mse:.4f}')\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "# Configuration variables (modify these as needed)\n",
    "pgn_file = 'master_games.pgn'  # Path to your PGN file\n",
    "h5_file = 'chess_data.h5'      # Path to save/load HDF5 file\n",
    "model_file = 'chess_model.pth' # Path to save model\n",
    "num_epochs = 10               # Number of epochs to train\n",
    "batch_size = 128              # Batch size for training\n",
    "learning_rate = 0.001         # Learning rate\n",
    "\n",
    "# Run the conversion (uncomment to run)\n",
    "# convert_pgn(pgn_file, h5_file)\n",
    "\n",
    "# Train the model (uncomment to run)\n",
    "train_model(h5_file, model_file, num_epochs, batch_size, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b427b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "btp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
